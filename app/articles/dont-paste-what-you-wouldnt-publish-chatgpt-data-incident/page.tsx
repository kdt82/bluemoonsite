'use client';

import SupportModal from '../../components/SupportModal';
import Link from 'next/link';

export default function ChatGPTDataIncidentArticle() {
  const openModal = () => {
    window.dispatchEvent(new CustomEvent('openModal'));
  };

  return (
    <>
      <main className="bg-white">
        {/* Article Header */}
        <section className="bg-[var(--primary)] py-16">
          <div className="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
            <div className="text-center">
              <div className="flex items-center justify-center mb-4">
                <span className="inline-block bg-[var(--accent)] text-white text-sm px-3 py-1 rounded-full mr-4">
                  Cybersecurity
                </span>
                <span className="text-white text-sm">
                  10 min read • 29 November 2025
                </span>
              </div>
              <h1 className="text-3xl sm:text-4xl md:text-5xl font-bold text-white mb-4">
                “Don’t Paste What You Wouldn’t Publish”: What the ChatGPT Data Incident Means For Everyday Users
              </h1>
              <p className="text-xl text-white max-w-3xl mx-auto">
                The recent Mixpanel security incident involving OpenAI is a clear reminder of a simple rule: never put anything into ChatGPT (or any AI chatbot) that you wouldn’t be comfortable seeing leaked, logged, or reviewed one day.
              </p>
            </div>
          </div>
        </section>

        {/* Article Content */}
        <article className="py-16">
          <div className="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
            <div className="prose prose-lg max-w-none">
              <p className="text-xl text-gray-700 mb-8 leading-relaxed">
                Even though this particular incident did not expose chat histories or passwords, it shows how easily data shared with “trusted” services can spread to third parties, and then be caught up in a breach.
              </p>
              <p className="text-gray-700 mb-8 leading-relaxed">
                This article explains, in plain language, what happened, what it means for you as a normal user, and which kinds of information you should never paste into ChatGPT.
              </p>

              {/* Article Image */}
              <div className="my-12 text-center">
                <img 
                  src="/assets/gptdatabreach.jpg" 
                  alt="Cybersecurity concept showing system locked and access denied" 
                  className="mx-auto max-w-full h-auto rounded-lg shadow-lg"
                  style={{ maxHeight: '400px' }}
                />
              </div>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">1. What actually happened in the Mixpanel incident?</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                OpenAI recently disclosed that a third‑party analytics provider it used, Mixpanel, suffered a security incident. Mixpanel is a company that helps websites and apps track how people use their products.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Here are the key facts:
              </p>
              
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li><strong>Where the breach happened:</strong> In Mixpanel’s systems, not inside OpenAI’s own servers.</li>
                <li><strong>Who was affected:</strong> Users of OpenAI’s API platform (developers and organizations using platform.openai.com), not ordinary ChatGPT users on chat.openai.com.</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">What was exposed:</h3>
              <p className="text-gray-700 mb-4 leading-relaxed">
                Limited profile and analytics data about those API accounts – for example:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Names associated with API accounts</li>
                <li>Email addresses</li>
                <li>Approximate location (city/state/country, inferred from IP/browser)</li>
                <li>Browser and operating system details</li>
                <li>Referring websites (where you came from)</li>
                <li>OpenAI organization or user IDs tied to those accounts</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">What was not exposed:</h3>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Chat conversations</li>
                <li>API requests or responses (what was sent to or generated by the model)</li>
                <li>Passwords or credentials</li>
                <li>API keys</li>
                <li>Payment details</li>
                <li>Government IDs</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">Timeline (simplified):</h3>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li><strong>9 November 2025:</strong> Mixpanel detects an attacker accessing part of its systems and exporting a dataset with customer‑identifiable analytics data.</li>
                <li><strong>25 November 2025:</strong> Mixpanel shares the impacted dataset with OpenAI, who begins analyzing and notifying affected users.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Shortly afterwards, OpenAI removes Mixpanel from its production environment and starts broader security reviews of its vendors.
              </p>
              <div className="bg-blue-50 border-l-4 border-blue-500 p-4 my-8">
                <p className="text-blue-700">
                  <strong>In short:</strong> this incident did not leak your ChatGPT chats, passwords, or payment information. It did, however, expose identity‑related metadata (like names and emails) about API users through a third‑party analytics provider.
                </p>
              </div>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">2. “If chats weren’t leaked, why should I care?”</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                It’s easy to shrug and think: “So what? It was just emails and some tech details.” But there are three big reasons this matters, even if you never touched the API.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">2.1 Third parties multiply your risk</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                When you use a service like ChatGPT, your data doesn’t just live in one neat box. It can be copied into:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Internal logs</li>
                <li>Monitoring systems</li>
                <li>Analytics tools</li>
                <li>Error tracking and performance tools</li>
                <li>Third‑party vendors and partners</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                The Mixpanel incident is a textbook example of indirect exposure: even though OpenAI’s own systems were not breached, data that OpenAI sent to Mixpanel was.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                That means:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Your risk is not only about whether OpenAI is secure.</li>
                <li>It is also about whether every vendor and sub‑vendor they rely on is secure – and whether those vendors minimize what they collect.</li>
                <li>The more places your data is copied to, the more doors there are for attackers.</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">2.2 “Just” names and emails are enough for serious attacks</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Attackers don’t always need your password or credit card number. For many scams, names + email addresses + rough location are more than enough to get started.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                With this kind of data, a criminal can:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Craft convincing phishing emails that look like they’re from OpenAI, your employer, or a developer tool you actually use.</li>
                <li>Target you with location‑aware scams, referencing your city or country to seem more legitimate.</li>
                <li>Impersonate you or your organization, especially if they also know you use OpenAI’s API for work.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                That’s why OpenAI and security experts are warning affected users to watch for phishing and social‑engineering attempts, even though no passwords or API keys were leaked.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">2.3 This is a warning sign for the future</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Nothing about this incident suggests mass leakage of ChatGPT conversations. But it is a reminder of a more general truth:
              </p>
              <div className="bg-orange-50 border-l-4 border-orange-500 p-4 my-8">
                <p className="text-orange-800">
                  Once your data leaves your device and goes into a large online system, you lose full control over where it travels and who might eventually see it.
                </p>
              </div>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Today it’s an analytics provider. Tomorrow it might be a logging tool, a customer support system, a backup service, or a future bug in the main product itself.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If you’ve ever told ChatGPT something that would genuinely damage you if it leaked, this should be your cue to reconsider how you use AI tools.
              </p>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">3. How AI tools like ChatGPT actually handle your data</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                To understand why you shouldn’t paste highly sensitive information into ChatGPT, it helps to know what generally happens under the hood, regardless of specific incidents.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Details can vary by product, plan, and settings, but in broad strokes:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li><strong>Your prompts and responses are stored.</strong> Most cloud‑based AI tools keep logs of your conversations for some period of time, for reasons such as debugging, abuse detection, or product improvement.</li>
                <li><strong>Humans may review some content.</strong> Companies may use human reviewers, under strict controls, to check for abuse, improve the model, or investigate safety issues. That means real people could see snippets of your conversations in some circumstances.</li>
                <li><strong>Data can be used to improve models (depending on terms and settings).</strong> In many consumer products, your conversations may be used (often in anonymized or aggregated form) to train and refine AI systems, unless you’re on a plan or have settings that say otherwise.</li>
                <li><strong>Data may be shared with vendors.</strong> Just like Mixpanel, other tools might receive parts of your data, logs, or metadata — for analytics, security, or performance monitoring.</li>
                <li><strong>Legal and regulatory access is possible.</strong> Like any large tech company, AI providers can be compelled to hand over certain data when responding to lawful requests, investigations, or litigation.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                The key point: none of this is unique to OpenAI. It’s how modern cloud services generally work. The only way to be absolutely sure a secret remains private is never to send it to an online service in the first place.
              </p>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">4. What you should never put into ChatGPT</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                For everyday users, the safest mindset is:
              </p>
              <div className="bg-purple-50 border-l-4 border-purple-500 p-4 my-8">
                <p className="text-purple-800">
                  Treat ChatGPT like a crowded café: don’t shout anything you wouldn’t be okay with strangers overhearing or seeing pinned on a public noticeboard.
                </p>
              </div>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Here are concrete examples of what not to paste into ChatGPT (or any similar AI tool).
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">4.1 Information that could enable identity theft</h3>
              <p className="text-gray-700 mb-4 leading-relaxed">
                Avoid providing:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Full legal name + date of birth + home address together</li>
                <li>Government ID numbers (passport, driver’s licence, national ID, tax file number, Social Security number, etc.)</li>
                <li>Bank account details, credit card numbers, CVV codes, or BSB/branch numbers</li>
                <li>Full scans or photos of IDs, bills, or banking documents</li>
                <li>Secret recovery phrases, private keys, crypto wallet seeds, or 2FA backup codes</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Even if the service promises not to train on this data, logs and backups exist, and future incidents or bugs could expose them.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">4.2 Login and security information</h3>
              <p className="text-gray-700 mb-4 leading-relaxed">
                Never paste:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Passwords (even “temporary” ones)</li>
                <li>One‑time codes from SMS or authenticator apps</li>
                <li>Security questions and answers (“What is your mother’s maiden name?” etc.)</li>
                <li>Internal VPN, Wi‑Fi, or shared account credentials</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If you need help creating a strong password, ask ChatGPT to generate an example – but don’t use that exact password for any real account.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">4.3 Highly sensitive personal stories</h3>
              <p className="text-gray-700 mb-4 leading-relaxed">
                Be extremely cautious with:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Detailed mental health, medical, or therapy histories tied to your real identity</li>
                <li>Stories of abuse, trauma, or highly personal events that name real people and places</li>
                <li>Information about your children (names, schools, routines, health issues)</li>
                <li>Confessions that could seriously damage your career, relationships, or legal standing if exposed</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                It’s understandable to want a chatbot that “listens” without judgment. But remember: your words can be logged, reviewed, or one day exposed through an unexpected path.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If you want to explore sensitive topics, consider:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Speaking in broad, fictionalized terms (e.g., “Person A”, “Person B”, “a small town”, “a colleague”)</li>
                <li>Stripping out names, addresses, workplace details, and exact dates</li>
                <li>Keeping the emotional content but removing specific identifiers</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">4.4 Your employer’s or clients’ secrets</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Many people now use ChatGPT at work — which is exactly where oversharing can be most dangerous.
              </p>
              <p className="text-gray-700 mb-4 leading-relaxed">
                Avoid pasting:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Internal documents marked confidential or sensitive</li>
                <li>Unreleased product designs, roadmaps, or strategy decks</li>
                <li>Source code owned by your employer or clients (especially proprietary or security‑related code)</li>
                <li>Legal documents under NDA or active litigation</li>
                <li>Customer data, CRM exports, internal emails, or spreadsheets with real names, contact details, or purchase histories</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Even if you “trust” a platform, you might still be violating your employment contract, professional ethics, or privacy laws by sharing this data.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If you must use an AI assistant at work:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Use official, approved tools and settings provided by your organization.</li>
                <li>Confirm how data is stored and whether it is used for model training.</li>
                <li>Redact or anonymize anything that could identify real people or confidential business details.</li>
              </ul>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">4.5 Anything you promised to keep private</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If someone gave you information in confidence — a friend’s story, a client’s situation, a partner’s secret — do not paste it into a chatbot, even if you change their name.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Often there will be small details (location, job, specific life events) that can still make them identifiable to someone who knows them.
              </p>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">5. Safer ways to use ChatGPT without oversharing</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                The goal is not to scare you away from using AI tools altogether. Used wisely, they can be extremely helpful. The trick is to separate “what you need help with” from the personal or secret details attached to it.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Here are practical habits that keep you safer.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">5.1 Anonymize your questions</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Before pasting text into ChatGPT, take 30 seconds to strip or blur identifiers:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Replace real names with neutral labels: “Alice” → “Person A”, “our CTO”, “my manager”.</li>
                <li>Remove addresses, phone numbers, email addresses, licence plates, and exact places.</li>
                <li>Generalize dates and locations: “1 March 2024 in Melbourne” → “earlier this year in a major city”.</li>
                <li>Delete unique ID numbers or customer codes.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                You’ll often find the AI can still give you the help you need without needing to know exactly who or where you are talking about.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">5.2 Ask for structure, not judgment</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Instead of pasting a full, raw personal story, you can ask for help in a more abstract way:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>“How can someone prepare to tell a close friend difficult news?”</li>
                <li>“What are some ways to manage anxiety before a medical appointment?”</li>
                <li>“How should a person handle a conflict with their boss about workload?”</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                You get general strategies and language that you can then apply in your real situation, without ever exposing the actual details.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">5.3 Use synthetic or scrubbed data for work</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                If you’re testing prompts for code, contracts, or business workflows:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Replace real customer data with fake but realistic examples.</li>
                <li>Use dummy emails like example@company.com instead of real ones.</li>
                <li>Swap real figures for similar‑scale but made‑up numbers.</li>
                <li>Obscure any API keys, access tokens, or secret URLs.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                This way, even if that prompt were somehow exposed later, it wouldn’t contain live secrets.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">5.4 Check what options your account or employer provides</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Depending on your plan and organization, there may be:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Opt‑out controls for using your data to train models.</li>
                <li>Enterprise or business offerings with stricter data isolation and no training on your content.</li>
                <li>Internal AI tools hosted by your company that keep data on infrastructure they control.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                None of this removes the need for common sense, but it can meaningfully reduce risk if used correctly.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">5.5 Remember that deletion isn’t a magic eraser</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Many services allow you to delete conversations, which is good practice. But:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Backups and logs may persist for some time.</li>
                <li>Data already processed or used for training may not be fully removed.</li>
                <li>Third‑party tools (like Mixpanel in this incident) may already have captured related metadata.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Treat deletion as reducing your exposure, not guaranteeing that something never existed.
              </p>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">6. “But if they say chats weren’t leaked, isn’t it safe?”</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                For this specific incident, OpenAI and independent reports are clear: no chat content was part of the exposed dataset, and typical ChatGPT users were not directly affected.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                However, equating “not leaked this time” with “safe to share anything” is risky thinking.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Here’s why that mindset is dangerous:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li><strong>Security is a moving target.</strong> Today’s secure system can have tomorrow’s zero‑day bug, misconfiguration, or malicious insider.</li>
                <li><strong>Vendors change.</strong> New partners, new tools, and new features can introduce new data flows that you’re never explicitly told about.</li>
                <li><strong>Your risk tolerance changes.</strong> Something that felt harmless to share last year (“help me draft a resignation email to X at Y company”) might feel disastrous if you later realize it’s stored somewhere.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                A safer mental model is:
              </p>
              <div className="bg-red-50 border-l-4 border-red-500 p-4 my-8">
                <p className="text-red-800">
                  Assume anything you type into a cloud‑based AI could, in a worst‑case scenario, be exposed or reviewed. Then decide whether you’re comfortable with that before you hit “send”.
                </p>
              </div>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">7. What this incident teaches ordinary users</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Even though the Mixpanel breach mostly concerns API users and metadata, it carries lessons for everyone who uses AI tools.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">7.1 Your data is only as safe as the weakest link</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                OpenAI stresses that its own systems were not breached; the problem was at a third‑party analytics vendor.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                From a user’s perspective, that distinction doesn’t matter much. What matters is:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Data about your account existed outside the main system.</li>
                <li>That copy was less secure than you might have hoped.</li>
                <li>An attacker was able to export it.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                The same thing can happen in countless other apps and services you use daily. The more sensitive the data, the more worrying this pattern becomes.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">7.2 “Limited” data can still have unlimited consequences</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Security notifications often emphasize that “only limited data” was affected, to calm fears.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                But modern attacks are highly creative:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Your email and approximate location can be combined with other breaches to build detailed profiles.</li>
                <li>Knowledge that you use a particular service (like an AI API for work) can be leveraged in targeted spear‑phishing against your employer.</li>
                <li>Public information about your job or company plus leaked metadata can help attackers guess who to impersonate and what to request.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                When thinking about risk, focus less on what a single incident exposed, and more on how that data could be combined with everything else already out there.
              </p>

              <h3 className="text-2xl font-bold text-[var(--primary)] mt-8 mb-4">7.3 Privacy is not “on” or “off” – it’s a spectrum</h3>
              <p className="text-gray-700 mb-6 leading-relaxed">
                There is no magical line where something is perfectly safe on one side and totally unsafe on the other. Instead:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>Some information is low‑risk (e.g., “explain quantum computing like I’m 12”).</li>
                <li>Some information is medium‑risk (e.g., “help me write feedback to my colleague about missing deadlines,” with no names).</li>
                <li>Some information is extremely high‑risk (e.g., all the data necessary to open a bank account in your name).</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                The Mixpanel incident is a nudge to move more of your usage toward the low‑risk side of that spectrum.
              </p>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">8. A simple mental checklist before you hit “send”</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                Before sharing something with ChatGPT, pause for five seconds and ask:
              </p>
              <div className="bg-gray-50 p-6 rounded-lg border border-gray-200 my-6">
                <ul className="space-y-4">
                  <li className="flex items-start">
                    <span className="text-red-500 mr-2 font-bold">1.</span>
                    <span><strong>Could this be used to steal my identity, access my accounts, or answer security questions about me?</strong><br/>If yes, do not paste it.</span>
                  </li>
                  <li className="flex items-start">
                    <span className="text-red-500 mr-2 font-bold">2.</span>
                    <span><strong>Would I be embarrassed, harmed, or put at legal risk if this exact text appeared on a public website with my name attached?</strong><br/>If yes, either change the wording to remove identifiers or reconsider sharing it at all.</span>
                  </li>
                  <li className="flex items-start">
                    <span className="text-red-500 mr-2 font-bold">3.</span>
                    <span><strong>Am I allowed to share this on behalf of my employer or client?</strong><br/>If you’re not sure, assume the answer is no until you check.</span>
                  </li>
                  <li className="flex items-start">
                    <span className="text-green-500 mr-2 font-bold">4.</span>
                    <span><strong>Can I get the same help without sharing the sensitive bits?</strong><br/>Often the answer is yes, with a little anonymization or reframing.</span>
                  </li>
                </ul>
              </div>

              <h2 className="text-3xl font-bold text-[var(--primary)] mt-12 mb-6">9. Key takeaways</h2>
              <p className="text-gray-700 mb-6 leading-relaxed">
                To put it all together:
              </p>
              <ul className="list-disc list-inside text-gray-700 mb-6 space-y-2">
                <li>The Mixpanel incident exposed names, emails, and other metadata about OpenAI API users, not ChatGPT chat logs, passwords, or payment data.</li>
                <li>It happened at a third‑party analytics provider, not inside OpenAI’s core systems — but from a user’s perspective, it still means data entrusted to the ecosystem ended up in a breach.</li>
                <li>Even “basic” data like names and emails can power phishing, impersonation, and social‑engineering attacks, especially when combined with other datasets.</li>
                <li>AI tools, like most cloud services, log and store your interactions, may share some data with vendors, and can be subject to human review and legal access.</li>
              </ul>
              <p className="text-gray-700 mb-6 leading-relaxed">
                As a result, you should never paste anything into ChatGPT that you would be devastated to see leak: no identity documents, financial info, passwords, children’s details, employer secrets, or deeply identifying personal confessions.
              </p>
              <p className="text-gray-700 mb-6 leading-relaxed">
                You can still benefit from AI by anonymizing your questions, using fictionalized examples, and sticking to low‑risk content whenever possible.
              </p>
              <div className="bg-green-50 border-l-4 border-green-500 p-4 my-8">
                <p className="text-green-800 font-bold">
                  In practice, the safest rule of thumb is this: If you wouldn’t be comfortable seeing your prompt on the front page of a major news site with your name next to it, don’t paste it into ChatGPT.
                </p>
              </div>
            </div>
          </div>
        </article>

        {/* Call to Action */}
        <section className="py-16 bg-[var(--primary)]">
          <div className="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
            <h2 className="text-3xl font-bold text-white mb-4">
              Concerned About Your Data Security?
            </h2>
            <p className="text-xl text-white mb-8 max-w-2xl mx-auto">
              Blue Moon IT can help you secure your personal and business data against modern threats. From secure network setups to cybersecurity audits, we have you covered.
            </p>
            
            <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
              <div className="bg-slate-800 bg-opacity-80 rounded-lg p-6 border border-slate-600">
                <div className="mb-4">
                  <svg xmlns="http://www.w3.org/2000/svg" className="h-12 w-12 mx-auto text-blue-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={1.5} d="M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z" />
                  </svg>
                </div>
                <h3 className="text-lg font-semibold mb-2 text-white">Cybersecurity Audits</h3>
                <p className="text-sm text-gray-200">Identify vulnerabilities in your home or business network before attackers do.</p>
              </div>
              
              <div className="bg-slate-800 bg-opacity-80 rounded-lg p-6 border border-slate-600">
                <div className="mb-4">
                  <svg xmlns="http://www.w3.org/2000/svg" className="h-12 w-12 mx-auto text-blue-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={1.5} d="M12 15v2m-6 4h12a2 2 0 002-2v-6a2 2 0 00-2-2H6a2 2 0 00-2 2v6a2 2 0 002 2zm10-10V7a4 4 0 00-8 0v4h8z" />
                  </svg>
                </div>
                <h3 className="text-lg font-semibold mb-2 text-white">Data Protection</h3>
                <p className="text-sm text-gray-200">Implement robust backup and encryption strategies to keep your sensitive data safe.</p>
              </div>
              
              <div className="bg-slate-800 bg-opacity-80 rounded-lg p-6 border border-slate-600">
                <div className="mb-4">
                  <svg xmlns="http://www.w3.org/2000/svg" className="h-12 w-12 mx-auto text-blue-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={1.5} d="M19.428 15.428a2 2 0 00-1.022-.547l-2.384-.477a6 6 0 00-3.86.517l-.318.158a6 6 0 01-3.86.517L6.05 15.21a2 2 0 00-1.806.547M8 4h8l-1 1v5.172a2 2 0 00.586 1.414l5 5c1.26 1.26.367 3.414-1.415 3.414H4.828c-1.782 0-2.674-2.154-1.414-3.414l5-5A2 2 0 009 10.172V5L8 4z" />
                  </svg>
                </div>
                <h3 className="text-lg font-semibold mb-2 text-white">Secure Network Setup</h3>
                <p className="text-sm text-gray-200">Professional installation of firewalls and secure Wi-Fi to block unauthorized access.</p>
              </div>
            </div>
            
            <div className="flex flex-col sm:flex-row justify-center gap-4">
              <Link 
                href="/services/cyber-security"
                className="bg-white hover:bg-gray-100 text-[var(--primary)] px-8 py-3 rounded-md shadow-md hover:shadow-lg transition-all duration-300 font-semibold"
              >
                Cybersecurity Services
              </Link>
              <button 
                onClick={openModal}
                className="accent-gradient text-white px-8 py-3 rounded-md shadow-md hover:shadow-lg transition-all duration-300 font-semibold"
              >
                Contact Us Today
              </button>
            </div>
            
            <p className="text-white mt-8 opacity-80">
              Serving the Illawarra, Wollongong, Shoalhaven, Eurobodalla and Southern Highlands regions.
            </p>
          </div>
        </section>
      </main>
      <SupportModal />
    </>
  );
}
